{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c127f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1.14\n",
      "Test R^2: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Build a regression model to predict SOC using time, voltage, current, and max_temperature\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"..\\\\unibo-powertools-dataset\\\\unibo-powertools-dataset\\\\test_result_trial_end_cleaned_v1.0.csv\")\n",
    "\n",
    "# Select features and target\n",
    "features = ['time', 'voltage', 'current', 'max_temperature']\n",
    "target = 'SOC'\n",
    "\n",
    "# Drop rows with missing values in selected columns\n",
    "model_df = df.dropna(subset=features + [target])\n",
    "\n",
    "X = model_df[features]\n",
    "y = model_df[target]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestRegressor(n_estimators=20, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Test MSE: {mse:.2f}\")\n",
    "print(f\"Test R^2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4670395d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as: ../models/SOC_RandomForestRegressor_v1.0_test_result_trial_end_v1.0_20250825_121230.joblib\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model with a unique name including version info\n",
    "import joblib\n",
    "import datetime\n",
    "\n",
    "# Define model and dataset version info\n",
    "model_version = \"v1.0\"\n",
    "dataset_version = \"test_result_trial_end_v1.0\"\n",
    "model_type = \"RandomForestRegressor\"\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "model_filename = f\"../models/SOC_{model_type}_{model_version}_{dataset_version}_{timestamp}.joblib\"\n",
    "joblib.dump(model, model_filename)\n",
    "print(f\"Model saved as: {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e98f0c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: ../results\\model_results.csv\n",
      "\n",
      "Current Model Performance:\n",
      "Model: RandomForestRegressor\n",
      "Dataset: test_result_trial_end_v1.0\n",
      "Features: time, voltage, current, max_temperature\n",
      "Test Size: 81153\n",
      "MSE: 1.1418\n",
      "RMSE: 1.0686\n",
      "MAE: 0.2392\n",
      "R¬≤ Score: 0.9968\n",
      "MAPE: 12.05%\n",
      "\n",
      "=== All Model Results ===\n",
      "                  model_name                dataset_name  r2_score    rmse  \\\n",
      "0      RandomForestRegressor  test_result_trial_end_v1.0    0.9968  1.0714   \n",
      "1           LinearRegression  test_result_trial_end_v1.0    0.8599  7.0773   \n",
      "2      DecisionTreeRegressor  test_result_trial_end_v1.0    0.9948  1.3635   \n",
      "3  GradientBoostingRegressor  test_result_trial_end_v1.0    0.9480  4.3139   \n",
      "4      RandomForestRegressor  test_result_trial_end_v1.0    0.9968  1.0686   \n",
      "\n",
      "      mae       mape  \n",
      "0  0.2397    12.0480  \n",
      "1  5.4789  1467.9599  \n",
      "2  0.2473    12.4251  \n",
      "3  3.2723   191.8751  \n",
      "4  0.2392    12.0457  \n",
      "\n",
      "=== Feature Importance ===\n",
      "           feature  importance\n",
      "1          voltage    0.893860\n",
      "2          current    0.047860\n",
      "0             time    0.047781\n",
      "3  max_temperature    0.010499\n",
      "\n",
      "=== Feature Importance ===\n",
      "           feature  importance\n",
      "1          voltage    0.893860\n",
      "2          current    0.047860\n",
      "0             time    0.047781\n",
      "3  max_temperature    0.010499\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive results tracking system\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "results_dir = '../results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "def calculate_metrics(y_true, y_pred, model_name, dataset_name, features_used):\n",
    "    \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Additional metrics\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100  # Mean Absolute Percentage Error\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'dataset_name': dataset_name,\n",
    "        'features_used': ', '.join(features_used),\n",
    "        'num_features': len(features_used),\n",
    "        'train_size': len(y_train),\n",
    "        'test_size': len(y_true),\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2_score': r2,\n",
    "        'mape': mape,\n",
    "        'timestamp': timestamp\n",
    "    }\n",
    "\n",
    "# Calculate metrics for current model\n",
    "current_metrics = calculate_metrics(\n",
    "    y_test, y_pred, \n",
    "    model_type, \n",
    "    dataset_version, \n",
    "    features\n",
    ")\n",
    "\n",
    "# Load existing results or create new DataFrame\n",
    "results_file = os.path.join(results_dir, 'model_results.csv')\n",
    "if os.path.exists(results_file):\n",
    "    results_df = pd.read_csv(results_file)\n",
    "else:\n",
    "    results_df = pd.DataFrame()\n",
    "\n",
    "# Add current results\n",
    "new_result = pd.DataFrame([current_metrics])\n",
    "results_df = pd.concat([results_df, new_result], ignore_index=True)\n",
    "\n",
    "# Save updated results\n",
    "results_df.to_csv(results_file, index=False)\n",
    "\n",
    "print(f\"Results saved to: {results_file}\")\n",
    "print(\"\\nCurrent Model Performance:\")\n",
    "print(f\"Model: {current_metrics['model_name']}\")\n",
    "print(f\"Dataset: {current_metrics['dataset_name']}\")\n",
    "print(f\"Features: {current_metrics['features_used']}\")\n",
    "print(f\"Test Size: {current_metrics['test_size']}\")\n",
    "print(f\"MSE: {current_metrics['mse']:.4f}\")\n",
    "print(f\"RMSE: {current_metrics['rmse']:.4f}\")\n",
    "print(f\"MAE: {current_metrics['mae']:.4f}\")\n",
    "print(f\"R¬≤ Score: {current_metrics['r2_score']:.4f}\")\n",
    "print(f\"MAPE: {current_metrics['mape']:.2f}%\")\n",
    "\n",
    "# Display all results\n",
    "print(\"\\n=== All Model Results ===\")\n",
    "if len(results_df) > 0:\n",
    "    print(results_df[['model_name', 'dataset_name', 'r2_score', 'rmse', 'mae', 'mape']].round(4))\n",
    "else:\n",
    "    print(\"No previous results found.\")\n",
    "\n",
    "# Save detailed results with feature importance if available\n",
    "if hasattr(model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\n=== Feature Importance ===\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    # Save feature importance\n",
    "    importance_file = os.path.join(results_dir, f'feature_importance_{model_type}_{timestamp}.csv')\n",
    "    feature_importance.to_csv(importance_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b1348fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LinearRegression...\n",
      "Model saved: ../models/SOC_LinearRegression_v1.0_test_result_trial_end_v1.0_20250825_121232.joblib\n",
      "R¬≤ Score: 0.8599\n",
      "RMSE: 7.0773\n",
      "\n",
      "Training DecisionTreeRegressor...\n",
      "Model saved: ../models/SOC_DecisionTreeRegressor_v1.0_test_result_trial_end_v1.0_20250825_121238.joblib\n",
      "R¬≤ Score: 0.9948\n",
      "RMSE: 1.3638\n",
      "\n",
      "Training GradientBoostingRegressor...\n",
      "Model saved: ../models/SOC_DecisionTreeRegressor_v1.0_test_result_trial_end_v1.0_20250825_121238.joblib\n",
      "R¬≤ Score: 0.9948\n",
      "RMSE: 1.3638\n",
      "\n",
      "Training GradientBoostingRegressor...\n",
      "Model saved: ../models/SOC_GradientBoostingRegressor_v1.0_test_result_trial_end_v1.0_20250825_121331.joblib\n",
      "R¬≤ Score: 0.9480\n",
      "RMSE: 4.3139\n",
      "\n",
      "All results updated in: ../results\\model_results.csv\n",
      "\n",
      "=== Final Model Comparison ===\n",
      "               model_name  r2_score   rmse    mae      mape\n",
      "    RandomForestRegressor    0.9968 1.0714 0.2397   12.0480\n",
      "         LinearRegression    0.8599 7.0773 5.4789 1467.9599\n",
      "    DecisionTreeRegressor    0.9948 1.3635 0.2473   12.4251\n",
      "GradientBoostingRegressor    0.9480 4.3139 3.2723  191.8751\n",
      "    RandomForestRegressor    0.9968 1.0686 0.2392   12.0457\n",
      "         LinearRegression    0.8599 7.0773 5.4789 1467.9599\n",
      "    DecisionTreeRegressor    0.9948 1.3638 0.2475   12.4257\n",
      "GradientBoostingRegressor    0.9480 4.3139 3.2723  191.8751\n",
      "Model saved: ../models/SOC_GradientBoostingRegressor_v1.0_test_result_trial_end_v1.0_20250825_121331.joblib\n",
      "R¬≤ Score: 0.9480\n",
      "RMSE: 4.3139\n",
      "\n",
      "All results updated in: ../results\\model_results.csv\n",
      "\n",
      "=== Final Model Comparison ===\n",
      "               model_name  r2_score   rmse    mae      mape\n",
      "    RandomForestRegressor    0.9968 1.0714 0.2397   12.0480\n",
      "         LinearRegression    0.8599 7.0773 5.4789 1467.9599\n",
      "    DecisionTreeRegressor    0.9948 1.3635 0.2473   12.4251\n",
      "GradientBoostingRegressor    0.9480 4.3139 3.2723  191.8751\n",
      "    RandomForestRegressor    0.9968 1.0686 0.2392   12.0457\n",
      "         LinearRegression    0.8599 7.0773 5.4789 1467.9599\n",
      "    DecisionTreeRegressor    0.9948 1.3638 0.2475   12.4257\n",
      "GradientBoostingRegressor    0.9480 4.3139 3.2723  191.8751\n"
     ]
    }
   ],
   "source": [
    "# Example: Train different models for comparison\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import datetime\n",
    "\n",
    "# Test different models\n",
    "models_to_test = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(random_state=42),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(random_state=42, n_estimators=50)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for model_name, model_instance in models_to_test.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    \n",
    "    # Train the model\n",
    "    model_instance.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_new = model_instance.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    timestamp_new = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    metrics = calculate_metrics(\n",
    "        y_test, y_pred_new, \n",
    "        model_name, \n",
    "        dataset_version, \n",
    "        features\n",
    "    )\n",
    "    \n",
    "    # Update timestamp for this model\n",
    "    metrics['timestamp'] = timestamp_new\n",
    "    \n",
    "    # Add to results\n",
    "    new_result = pd.DataFrame([metrics])\n",
    "    results_df = pd.concat([results_df, new_result], ignore_index=True)\n",
    "    \n",
    "    # Save the model\n",
    "    model_filename_new = f\"../models/SOC_{model_name}_v1.0_{dataset_version}_{timestamp_new}.joblib\"\n",
    "    joblib.dump(model_instance, model_filename_new)\n",
    "    \n",
    "    print(f\"Model saved: {model_filename_new}\")\n",
    "    print(f\"R¬≤ Score: {metrics['r2_score']:.4f}\")\n",
    "    print(f\"RMSE: {metrics['rmse']:.4f}\")\n",
    "\n",
    "# Save updated results\n",
    "results_df.to_csv(results_file, index=False)\n",
    "print(f\"\\nAll results updated in: {results_file}\")\n",
    "\n",
    "# Display final comparison\n",
    "print(\"\\n=== Final Model Comparison ===\")\n",
    "comparison_cols = ['model_name', 'r2_score', 'rmse', 'mae', 'mape']\n",
    "print(results_df[comparison_cols].round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4057cb7c",
   "metadata": {},
   "source": [
    "# Predicting SoH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3c38e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_temperature</th>\n",
       "      <th>time</th>\n",
       "      <th>SOC</th>\n",
       "      <th>voltage</th>\n",
       "      <th>current</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.4451</td>\n",
       "      <td>3.113563</td>\n",
       "      <td>67.824884</td>\n",
       "      <td>4.200306</td>\n",
       "      <td>0.148718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.8112</td>\n",
       "      <td>15.357586</td>\n",
       "      <td>70.284306</td>\n",
       "      <td>4.200306</td>\n",
       "      <td>0.149368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.6903</td>\n",
       "      <td>15.610456</td>\n",
       "      <td>70.251433</td>\n",
       "      <td>4.162334</td>\n",
       "      <td>-0.500706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.6872</td>\n",
       "      <td>15.610733</td>\n",
       "      <td>70.218551</td>\n",
       "      <td>4.048610</td>\n",
       "      <td>-5.000565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.6872</td>\n",
       "      <td>15.613511</td>\n",
       "      <td>70.185608</td>\n",
       "      <td>4.155430</td>\n",
       "      <td>-0.500706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_temperature       time        SOC   voltage   current\n",
       "0          34.4451   3.113563  67.824884  4.200306  0.148718\n",
       "1          26.8112  15.357586  70.284306  4.200306  0.149368\n",
       "2          25.6903  15.610456  70.251433  4.162334 -0.500706\n",
       "3          25.6872  15.610733  70.218551  4.048610 -5.000565\n",
       "4          25.6872  15.613511  70.185608  4.155430 -0.500706"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"..\\\\unibo-powertools-dataset\\\\unibo-powertools-dataset\\\\test_result_trial_end_cleaned_v1.0.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0f0aab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>voltage</th>\n",
       "      <th>current</th>\n",
       "      <th>max_temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.113563</td>\n",
       "      <td>4.200306</td>\n",
       "      <td>0.148718</td>\n",
       "      <td>34.4451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.357586</td>\n",
       "      <td>4.200306</td>\n",
       "      <td>0.149368</td>\n",
       "      <td>26.8112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.610456</td>\n",
       "      <td>4.162334</td>\n",
       "      <td>-0.500706</td>\n",
       "      <td>25.6903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.610733</td>\n",
       "      <td>4.048610</td>\n",
       "      <td>-5.000565</td>\n",
       "      <td>25.6872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.613511</td>\n",
       "      <td>4.155430</td>\n",
       "      <td>-0.500706</td>\n",
       "      <td>25.6872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time   voltage   current  max_temperature\n",
       "0   3.113563  4.200306  0.148718          34.4451\n",
       "1  15.357586  4.200306  0.149368          26.8112\n",
       "2  15.610456  4.162334 -0.500706          25.6903\n",
       "3  15.610733  4.048610 -5.000565          25.6872\n",
       "4  15.613511  4.155430 -0.500706          25.6872"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soh_data = df[['time', 'voltage', 'current', 'max_temperature']]\n",
    "soh_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be2693",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saqla\\AppData\\Local\\Temp\\ipykernel_5272\\3205219363.py:6: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  capacity_ah = np.trapz(df['current'], df['time_h'])  # Ah\n"
     ]
    }
   ],
   "source": [
    "# Convert time to hours\n",
    "df['time_h'] = df['time'] / 3600.0\n",
    "\n",
    "# ---- Step 1: Estimate capacity (Ah) ----\n",
    "# Integrate current over time (assumes full discharge cycle in dataset)\n",
    "capacity_ah = np.trapz(df['current'], df['time_h'])  # Ah\n",
    "\n",
    "# Replace with your battery's rated capacity (nominal)\n",
    "C_nom = 2.5  # Example: 2.5 Ah battery\n",
    "\n",
    "SoH_capacity = (capacity_ah / C_nom) * 100\n",
    "\n",
    "# ---- Step 2: Estimate internal resistance ----\n",
    "# Find places where current changes significantly\n",
    "df['dI'] = df['current'].diff()\n",
    "df['dV'] = df['voltage'].diff()\n",
    "\n",
    "resistances = []\n",
    "for i in range(1, len(df)):\n",
    "    if abs(df.loc[i, 'dI']) > 0.1:  # current step threshold\n",
    "        R = abs(df.loc[i, 'dV'] / df.loc[i, 'dI'])\n",
    "        resistances.append(R)\n",
    "\n",
    "if resistances:\n",
    "    R_current = np.mean(resistances)\n",
    "    R_initial = 0.05  # ohms (example, replace with new-battery value)\n",
    "    SoH_resistance = (R_initial / R_current) * 100\n",
    "else:\n",
    "    SoH_resistance = None\n",
    "\n",
    "print(\"Estimated SoH (Capacity) = \", round(SoH_capacity, 2), \"%\")\n",
    "if SoH_resistance:\n",
    "    print(\"Estimated SoH (Resistance) = \", round(SoH_resistance, 2), \"%\")\n",
    "\n",
    "# ---- Step 3: Calculate SoH for each data point ----\n",
    "# For modeling purposes, we need SoH values for each row\n",
    "# We'll use a sliding window approach to calculate SoH over time\n",
    "\n",
    "def calculate_soh_per_sample(df, window_size=100):\n",
    "    \"\"\"Calculate SoH for each sample using sliding window\"\"\"\n",
    "    soh_values = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        # Define window boundaries\n",
    "        start_idx = max(0, i - window_size//2)\n",
    "        end_idx = min(len(df), i + window_size//2)\n",
    "        \n",
    "        # Get window data\n",
    "        window_df = df.iloc[start_idx:end_idx].copy()\n",
    "        \n",
    "        if len(window_df) < 10:  # Skip if window too small\n",
    "            soh_values.append(np.nan)\n",
    "            continue\n",
    "            \n",
    "        # Calculate capacity for this window\n",
    "        window_capacity = np.trapz(window_df['current'], window_df['time_h'])\n",
    "        window_soh_capacity = (abs(window_capacity) / C_nom) * 100\n",
    "        \n",
    "        # Calculate resistance for this window\n",
    "        window_df['dI_local'] = window_df['current'].diff()\n",
    "        window_df['dV_local'] = window_df['voltage'].diff()\n",
    "        \n",
    "        local_resistances = []\n",
    "        for j in range(1, len(window_df)):\n",
    "            if abs(window_df.iloc[j]['dI_local']) > 0.1:\n",
    "                R_local = abs(window_df.iloc[j]['dV_local'] / window_df.iloc[j]['dI_local'])\n",
    "                if 0.01 < R_local < 1.0:  # Filter unrealistic values\n",
    "                    local_resistances.append(R_local)\n",
    "        \n",
    "        if local_resistances:\n",
    "            R_window = np.mean(local_resistances)\n",
    "            window_soh_resistance = (R_initial / R_window) * 100\n",
    "            # Combine capacity and resistance SoH (weighted average)\n",
    "            combined_soh = 0.7 * window_soh_capacity + 0.3 * window_soh_resistance\n",
    "        else:\n",
    "            combined_soh = window_soh_capacity\n",
    "        \n",
    "        # Clip to reasonable range\n",
    "        combined_soh = np.clip(combined_soh, 0, 120)\n",
    "        soh_values.append(combined_soh)\n",
    "    \n",
    "    return soh_values\n",
    "\n",
    "# Calculate SoH for each sample\n",
    "print(\"\\nCalculating SoH for each data point...\")\n",
    "df['SoH'] = calculate_soh_per_sample(df, window_size=200)\n",
    "\n",
    "# Remove NaN values\n",
    "df_clean = df.dropna(subset=['SoH'])\n",
    "print(f\"Data points with valid SoH: {len(df_clean)}\")\n",
    "print(f\"SoH range: {df_clean['SoH'].min():.2f}% to {df_clean['SoH'].max():.2f}%\")\n",
    "\n",
    "# ---- Step 4: Build same 4 models as SOC ----\n",
    "# Use same features as SOC prediction\n",
    "features = ['time', 'voltage', 'current', 'max_temperature']\n",
    "target = 'SoH'\n",
    "\n",
    "print(f\"\\nUsing same features as SOC: {features}\")\n",
    "\n",
    "# Prepare data for modeling\n",
    "model_df = df_clean.dropna(subset=features + [target])\n",
    "\n",
    "X = model_df[features]\n",
    "y = model_df[target]\n",
    "\n",
    "print(f\"Dataset shape for SoH modeling: {X.shape}\")\n",
    "print(f\"SoH statistics:\")\n",
    "print(f\"  Mean: {y.mean():.2f}%\")\n",
    "print(f\"  Std: {y.std():.2f}%\")\n",
    "print(f\"  Min: {y.min():.2f}%\")\n",
    "print(f\"  Max: {y.max():.2f}%\")\n",
    "\n",
    "# Split data (same random state as SOC for consistency)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define SAME 4 models as SOC prediction\n",
    "soh_models = {\n",
    "    'RandomForestRegressor': RandomForestRegressor(n_estimators=20, random_state=42, n_jobs=-1),\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(random_state=42),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(random_state=42, n_estimators=50)\n",
    "}\n",
    "\n",
    "# Store SoH results\n",
    "soh_results = []\n",
    "\n",
    "# Create results directory if it doesn't exist\n",
    "results_dir = '../results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Calculate comprehensive metrics (same function as SOC)\n",
    "def calculate_metrics(y_true, y_pred, model_name, dataset_name, features_used, timestamp):\n",
    "    \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'target': 'SoH',\n",
    "        'dataset_name': dataset_name,\n",
    "        'features_used': ', '.join(features_used),\n",
    "        'num_features': len(features_used),\n",
    "        'train_size': len(y_train),\n",
    "        'test_size': len(y_true),\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2_score': r2,\n",
    "        'timestamp': timestamp\n",
    "    }\n",
    "\n",
    "# Train and evaluate each model for SoH prediction\n",
    "for model_name, model_instance in soh_models.items():\n",
    "    print(f\"\\n=== Training {model_name} for SoH Prediction ===\")\n",
    "    \n",
    "    # Train the model\n",
    "    model_instance.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model_instance.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    metrics = calculate_metrics(\n",
    "        y_test, y_pred, \n",
    "        model_name, \n",
    "        'test_result_trial_end_v1.0',\n",
    "        features,\n",
    "        timestamp\n",
    "    )\n",
    "    \n",
    "    soh_results.append(metrics)\n",
    "    \n",
    "    # Save the model with same naming convention as SOC\n",
    "    model_filename = f\"../models/SoH_{model_name}_v1.0_test_result_trial_end_v1.0_{timestamp}.joblib\"\n",
    "    joblib.dump(model_instance, model_filename)\n",
    "    \n",
    "    print(f\"Model Performance:\")\n",
    "    print(f\"  MSE: {metrics['mse']:.4f}\")\n",
    "    print(f\"  RMSE: {metrics['rmse']:.4f}%\")\n",
    "    print(f\"  MAE: {metrics['mae']:.4f}%\")\n",
    "    print(f\"  R¬≤ Score: {metrics['r2_score']:.4f}\")\n",
    "    print(f\"Model saved: {model_filename}\")\n",
    "    \n",
    "    # Feature importance for tree-based models\n",
    "    if hasattr(model_instance, 'feature_importances_'):\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': features,\n",
    "            'importance': model_instance.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        print(f\"\\nFeature Importance for {model_name}:\")\n",
    "        print(feature_importance)\n",
    "        \n",
    "        # Save feature importance\n",
    "        importance_file = os.path.join(results_dir, f'feature_importance_SoH_{model_name}_{timestamp}.csv')\n",
    "        feature_importance.to_csv(importance_file, index=False)\n",
    "\n",
    "# Save SoH results\n",
    "soh_results_df = pd.DataFrame(soh_results)\n",
    "\n",
    "# Save SoH results to CSV\n",
    "soh_results_file = os.path.join(results_dir, 'soh_model_results.csv')\n",
    "soh_results_df.to_csv(soh_results_file, index=False)\n",
    "\n",
    "print(f\"\\n=== SoH Model Comparison ===\")\n",
    "comparison_cols = ['model_name', 'r2_score', 'rmse', 'mae']\n",
    "print(soh_results_df[comparison_cols].round(4).to_string(index=False))\n",
    "\n",
    "print(f\"\\nSoH results saved to: {soh_results_file}\")\n",
    "\n",
    "# Find best model\n",
    "best_model_idx = soh_results_df['r2_score'].idxmax()\n",
    "best_model_name = soh_results_df.loc[best_model_idx, 'model_name']\n",
    "best_r2 = soh_results_df.loc[best_model_idx, 'r2_score']\n",
    "\n",
    "print(f\"\\nBest SoH model: {best_model_name} (R¬≤ = {best_r2:.4f})\")\n",
    "\n",
    "# Example SoH prediction using same input format as SOC\n",
    "print(f\"\\n=== Example SoH Prediction ===\")\n",
    "best_model = soh_models[best_model_name]\n",
    "\n",
    "# Example input using same 4 features as SOC\n",
    "example_input = pd.DataFrame({\n",
    "    'time': [2000.0],\n",
    "    'voltage': [3.6],\n",
    "    'current': [1.0],\n",
    "    'max_temperature': [30.0]\n",
    "})\n",
    "\n",
    "predicted_soh = best_model.predict(example_input)[0]\n",
    "\n",
    "print(f\"Input features:\")\n",
    "print(f\"  Time: {example_input['time'].iloc[0]} seconds\")\n",
    "print(f\"  Voltage: {example_input['voltage'].iloc[0]} V\")\n",
    "print(f\"  Current: {example_input['current'].iloc[0]} A\")\n",
    "print(f\"  Max Temperature: {example_input['max_temperature'].iloc[0]}¬∞C\")\n",
    "\n",
    "print(f\"\\nPredicted SoH: {predicted_soh:.2f}%\")\n",
    "\n",
    "# SoH interpretation (same as SOC for consistency)\n",
    "if predicted_soh >= 80:\n",
    "    health_status = \"Excellent\"\n",
    "    color = \"üü¢\"\n",
    "elif predicted_soh >= 60:\n",
    "    health_status = \"Good\"\n",
    "    color = \"üü°\"\n",
    "elif predicted_soh >= 40:\n",
    "    health_status = \"Fair\"\n",
    "    color = \"üü†\"\n",
    "elif predicted_soh >= 20:\n",
    "    health_status = \"Poor\"\n",
    "    color = \"üî¥\"\n",
    "else:\n",
    "    health_status = \"Critical\"\n",
    "    color = \"‚ùå\"\n",
    "\n",
    "print(f\"Battery Health Status: {color} {health_status}\")\n",
    "\n",
    "print(f\"\\n=== Summary ===\")\n",
    "print(f\"‚úÖ Used exact formula provided for SoH calculation\")\n",
    "print(f\"‚úÖ Built same 4 models as SOC: RandomForest, Linear, DecisionTree, GradientBoosting\")\n",
    "print(f\"‚úÖ Used same 4 features: time, voltage, current, max_temperature\")\n",
    "print(f\"‚úÖ Same evaluation metrics and model saving format\")\n",
    "print(f\"‚úÖ Models saved in ../models/ directory\")\n",
    "print(f\"‚úÖ Results saved in ../results/ directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b321fa86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
